\chapter{Material e Métodos}
\label{Materiais}

Mais do que uma simples aplicação Android, o projeto englobou o sensoreamento de sinais ultrassônicos, comunicação sem fio e um circuito gerenciado por um Arduíno. Por essa razão, diversos componentes eletrônicos e métodos de comunicação foram utilizados.	

Basicamente, o usuário do smartphone, por meio do aplicativo Android captura uma imagem daquilo que deseja obter informações. A imagem é enviada aos servidores em nuvem da Google, onde é processada e tem suas informações traduzidas lexicograficamente. O resultado é então transferido de volta para o smartphone e apresentado em forma textual apropriada sob a qual pode se obter uma audiodescrição. 

Por outro lado, um sensor conectado a um Arduíno emite ondas ultrassônicas periodicamente e retorna a distância estimada ao obstáculo. O resultado é então transferido ao smartphone, por meio de um módulo BlueTooth também conectado ao Arduíno, e a aplicação por fim alerta o usuário. A figura \ref{esquematico} apresenta um esquemático que exemplifica o funcionamento do sistema.

 \begin{figure}[H]
 	\centering
 	
 	\includegraphics[scale=0.35]{./Resources/esquematico1.jpg}
 	%\caption*{FONTE: Autor}
 	\captionof{figure}{Esquemático de comunicação entre os módulos eletrônicos do projeto}
 	\label{esquematico}
 \end{figure}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Materiais}

Os materiais utilizados, bem como a descrição detalhada de suas propriedades e sua função no projeto estão listados a seguir.

\subsection{Smartphone}
 \begin{figure}[H]
 	\centering
 	
 	\includegraphics[scale=0.35]{./Resources/smartphone.jpg}
 	\captionof{figure}{Smartphone Galaxy S3 mini}
 	\caption*{FONTE: www.tudocelular.com}
 	
 	\label{PhotoSmartphone}
 \end{figure}
O nó principal do sistema pode ser considerado o smartphone. Por ser um dispositivo multifuncional com câmera, saída de áudio, vibração e permitir a execução de aplicativos, além de possuir tamanho mais reduzido se comparado ao tablet, por exemplo, mostrou-se ideal para o propósito do projeto. Com a câmera foi possível a captura das imagens posteriormente tratadas para extração de informação. A saída de áudio em paralelo com a vibração foram essenciais para uma interface útil voltada para usuários com deficiência visual. O tamanho reduzido também foi importante para que o dispositivo pudesse manuseado e guardado facilmente no corpo. Bastou então o desenvolvimento de um aplicativo que gerenciasse todos os recursos de hardware necessários. O smartphone utilizado majoritariamente durante o desenvolvimento do projeto foi o Samsumg Galaxy S3 mini \ref{PhotoSmartphone}, cuja especificação técnica está descrita na tabela \ref{dataSmartphone}.

\begin{table}[]
	\centering
	\caption{Especificação técnica do smartphone utilizado no projeto}
	\label{dataSmartphone}
	\begin{tabular}{ll}
		   
		Sistema Operacional  & Android 4.1 Jelly Bean   \\
		Dimensões            & 121.55 x 63 x 9.85 mm    \\  
		Peso                 & 111.5 g 					\\   
		RAM                  & 1 GB   					\\    
		Memória              & 16 GB 					\\   
		Resolução - Câmera   & 2592 x 1944 pixel   		\\ 
     
	\end{tabular}
\end{table}

\subsection{Android Studio}
Uma vez que o smartphone escolhido para o projeto foi o Galaxy S3 mini, cujo sistema operacional é o Android, para a programação do aplicativo foi necessária a utilização da IDE Android Studio 1.4.

\subsection{Arduíno}

\begin{figure}[H]
	\centering
	
	\includegraphics[scale=0.35]{./Resources/arduino.jpg}
	\captionof{figure}{Arduíno UNO}
	\caption*{FONTE: www.arduino.cc}
	\label{PhotoArduino}
\end{figure}

Para a funcionalidade de detecção de obstáculos, que não poderia ser feita pelo smartphone, foi necessária a utilização de outro dispositivo. Para tanto, foi definido que essa funcionalidade poderia ser facilmente realizada pela placa de programação Arduíno UNO, figura \ref{PhotoArduino}. As especificações da placa estão na tabela \ref{dataArduino}.

\begin{table}[]
	\centering
	\caption{Especificação técnica Arduíno}
	\label{dataArduino}
	\begin{tabular}{ll}
		
		Microcontrolador     & ATmega328P   	\\
		Pinos de E/S         & 14           	\\  
		Dimensões			 & 68.6 x 53.4 mm	\\
		Peso                 & 25 g 			\\
		Flash Memory		 & 32 KB			\\
		SRAM				 & 2 KB				\\
		EEPROM				 & 1 KB 			\\  		
		
	\end{tabular}
\end{table}

\subsection{Sensor}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{./Resources/sensor.jpg}
	\caption{Sensor HC-SR04. FONTE: www.filipeflop.com}
	\label{PhotoSensor}
\end{figure}

O Arduíno como uma placa programável, possibilita um infinidade de aplicações. Entretanto ele não possui sensores acoplados, apenas entradas e saídas genéricas. Para a detecção de obstáculos foi necessária a inserção de um sensor. O HC-SR04, figura \ref{PhotoBlueTooth}, sensor ultrassônico que se mostrou eficiente para a tarefa desejada. Emitindo ondas de frequência ultrassônica, o sensor capta o sinal refletido e baseado na intensidade permite o cálculo da distância.

\subsection{BlueTooth}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{./Resources/bluetooth.jpg}
	\caption{Módulo BlueTooth HC-05. FONTE: www.filipeflop.com}
	\label{PhotoBlueTooth}
\end{figure}

Para a comunicação entre o Arduíno e o smartphone haviam diversas possibilidades de implementação. A troca de dados pela internet já seria utilizada pela aplicação Android para o reconhecimento de imagens, que será apresentado com mais detalhes na seção Métodos. No entanto, havia soluções mais simples, como por exemplo, a comunicação via BlueTooth, adota pelo projeto. Assim como o sensor, foi inserido ao circuito controlado pelo Arduíno o módulo BlueTooth HC-05, apresentado pela figura \ref{PhotoBlueTooth}.

\subsection{Componentes eletrônicos em geral}

Para a conexão dos componentes do circuito foram necessários uma variedade de fios. No total foram utilizados por volta de 10 unidades para conectar VCC, GND, emendas e conexões de entrada e saída de sinais. Foram necessários também resistores para criação de um divisor de tensão. Para tanto foram utilizados três resistores de 220$\Omega$ para transformar 5V em 3V. Além disso, para fixar os componentes e montar o circuito, foi utilizado uma mini placa de ensaio.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Métodos}

Os métodos utilizados para a se atingir o objetivo do projeto são extremamente importantes não só para a compreensão de como as partes se comunicam, mas também para se expor detalhes da implementação que são essenciais para garantir ampla usabilidade e acessibilidade do usuário.

\subsection{Configurações iniciais de programação}

Antes de tudo, para o início da programação do aplicativo foi necessária a instalação do Android Studio e para a programação da placa Arduíno, da IDE de mesmo nome. 

\subsection{Construção de interface acessível}

O objetivo do projeto era permitir que pessoas com limitações visuais pudessem exercer algumas funções exclusivas de pessoas que podem ver. Por essa razão, o ponto mais importante, e primeiro a ser planejado foi a interface. Então, a primeira coisa a ser feita era definir se o Android 4.1 permitiria a usabilidade por pessoas a qual o projeto se destina.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{./Resources/talkback.jpg}
	\caption{Talkback}
	\label{PhotoTalkback}
\end{figure}

A princípio, foi considerada a possibilidade de implementar tradução de texto em áudio pela aplicação. Dessa forma, qualquer informação na tela do aplicativo poderia ser descrita ao usuário pelo som. No entanto isso foi desnecessário quando entrou em cena o Talkback, figura \ref{PhotoTalkback}, serviço nativo do Android que adapta a lógica de interação para pessoas com dificuldades de visão. Além de fazer automaticamente a tradução texto-áudio de qualquer informação presente na tela, o Talkback muda a lógica de cliques e insere sons e vibrações de resposta a qualquer ação realizada, desde toques em botões até deslizamento em listas. Com isso, o projeto pode avançar para outro ponto importante da interface: o tamanho dos elementos.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.3]{./Resources/menu.png}
	\caption{Tela inicial do aplicativo}
	\label{menu}
\end{figure} 

Uma das dificuldades enfrentadas por essas pessoas ao utilizar aplicativos é selecionar o elemento correto na tela devido o tamanho reduzido em relação aos dedos. Por essa razão, o menu principal, Figura \ref{menu}, divide a tela toda em quatro grandes áreas que servem para posicionamento dos botões. Além disso, a barra de status do Android e de título do aplicativo foram ocultadas, para garantir o melhor aproveitamento de espaço da tela. 

Outro problema a ser considerado foi a navegabilidade. Um dos requisitos para que uma pessoa sem visão pudesse utilizar um aplicativo é saber onde está, ou seja, impedir que o usuário não se perdesse na sequência de menus. Por isso, além de não haver submenus na interface, o padrão de desenvolvimento de aplicações Android foi respeitado, com a inserção de descrição de conteúdo a todos os elementos da interface, como mostra a Figura \ref{nav}. Essas descrições ficam visualmente ocultas, mas são lidas apenas pelo Talkback, que transforma a informação em áudio.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{./Resources/navegabilidade.jpg}
	\caption{Tela principal e respectivas funcionalidades. (a) Descrição facial. (b) Extração de texto (c) Seleção de registros (d) Detecção de obstáculos}
	\label{nav}
\end{figure} 

Uma vez que o aplicativo não se limita a atender apenas pessoas com ausência total de visão, outro cenário considerado foi a utilização do aplicativo por pessoas com graus mais menos intensos de deficiência visual. Baseado na pesquisa de acessibilidade realizada por Shaun K. Kane et al com pessoas de diferentes graus de falta de visão, fontes de tamanho grande e o contraste de cores são considerados características importantes \cite{Kane}. Assim, um esquema de cores bastante fortes e contrastantes foram utilizadas. E cada cor utilizada nos botões do menu principal foi também utilizada como cor de fundo da interface correspondente à opção selecionada. Além disso, o tamanho das letras dos textos de resultado foi aumentado significativamente e formatado em negrito para facilitar uma possível leitura.

Implementadas todas as características de acessibilidade no aplicado, o resultado foi:


\begin{enumerate}
	\item Interface que permite áudio descrição;
	\item Menu principal, com apenas quatro botões e cores contrastantes;
	\item Botão que acessa a câmera e exibe a descrição com o máximo de informações da imagem capturada;
	\item Botão que acessa a câmera e exibe apenas textos da imagem capturada;
	\item Botão que leva a uma lista de descrições salvas e permite acessá-las;
	\item Botão que inicia conexão com o Arduíno;
	\item Menu de opções que permite inserir ou remover alguns sons/animações de resposta;
\end{enumerate}

\subsection{Extração de dados em imagem}

A solução adotada para o reconhecimento de dados em imagem foi o Cloud Vision, uma API em nuvem da Google de reconhecimento de imagens, e com gratuidade limitada ao número de requisições mensais, cujos valores podem ser encontrados na Tabela \ref{Price}. Como o projeto a princípio não é um produto e não é de grande porte, não exigiria muitas requisições e se mostrou uma solução muito adequada. 

\begin{figure}[H]
	\centering
	
	\captionof{table}{Preços da API Google Cloud Vision por quantidade e tipo de solicitação}
	\includegraphics[scale=0.4]{./Resources/price.png}
	\caption*{Fonte: Google Cloud Platform\cite{bestPracticesGoogle}}
	
	\label{Price}
	
\end{figure}

A API criada em 2015 apesar de muito potente e ter atraído muitos usuários interessados em automatizar a classificação de imagens, ainda não tem aparecido com muita frequência em trabalhos científicos. Entretanto, para demonstrar as capacidades da API, a Google apresentou na GCP NEXT 2016 o projeto Cloud Vision Explorer, um ambiente web galáctico contendo milhares de imagens separadas por categorias, que utiliza o Cloud Vision que é modelado pelo TensorFlow, uma biblioteca de software livre para inteligência de máquina também pertencente a Google \cite{Galaxy}.

Para se ter acesso aos serviços da Google Cloud, é necessário se cadastrar no sistema. Uma vez dentro do sistema, foi criado um projeto sobre o Vision API. Em seguida, para permitir a utilização desse projeto pela aplicação Android, foi necessário gerar uma chave de identificação de API. Por meio da importação dos pacotes em linguagem Java e dessa chave, bastou a construção de objeto de chamada de serviço no aplicativo. Logo depois, associou-se ao objeto a imagem fonte, o modo de compressão e de codificação da imagem a ser enviada, o português como idioma de identificação de textos e por fim as categorias que se poderia buscar na imagem, entre elas, texto, rótulo e expressões faciais. Com o objeto configurado, bastou enviar a requisição ao servidor da Google e aguardar o resultado. Ao final do processo, o retorno da requisição veio em um objeto contendo as informações pedidas separadas por categorias e suas respectivas pontuações de confiança. 

\subsection{Adaptação textual do dado retornado}

Após utilizar os serviços do Cloud Vision para a extração de informações da imagem, o passo seguinte foi adaptar as informações escritas para um conteúdo textual de fácil compreensão. O motivo é que as informações extraídas vinham em partes, separadas por categorias, nem sempre vinham preenchidas com informação, ou mesmo possuíam probabilidade baixa de estarem corretas podendo ser descartadas. Assim, foi necessário filtrar esses dados, adicionando um limite de 80\% de confiabilidade. Também, para garantir uma boa fluência no texto resultante, as informações foram filtradas por categoria e dependendo da qual pertencessem, produziriam uma saída textual específica.

\subsection{Tradução de rótulos}
Outra adaptação necessária foi em relação ao idioma. Apesar de a ferramenta ser capaz de identificar um infinidade deles, os resultados retornados de rótulos relacionadas a imagem estavam sempre em inglês. A solução encontrada foi traduzir esses rótulos antes de compor a saída textual final. No entanto, não há suporte diretamente do Android para essa funcionalidade, e seguindo o exemplo da solicitação de serviços online, a solução encontrada foi utilizar novamente alguma API de tradução. Como a API de tradução da Google não oferece faixa de solicitações gratuitas, o que é extremamente importante, utilizou-se em vez disso a API de tradução Yandex, figura \ref{Yandex}, que assim como a Cloud Vision oferecia um limite de gratuidade.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{./Resources/yandex.png}
	\caption{Interface gráfica do Tradutor Yandex acessado pelo navegador}
	\label{Yandex}
\end{figure}

\subsection{Captura e exibição de resultado}
O processo de descrição de imagem inicia-se em uma tela que exibe as imagens vindas da câmera traseira do smartphone. O aplicativo, porém, não requisita em momento algum acesso a câmera frontal. Com um toque, ou dois quando o Talkback está ativado, o aplicativo captura a imagem, a salva no dispositivo no formato JPG, em uma nova pasta dentro do diretório do aplicativo e a envia para a nuvem. Enquanto o aplicativo aguarda o retorno do serviço solicitado, uma imagem de relógio pisca suave e lentamente na tela, enquanto um som de tic-tac é tocado como forma de informar o usuário que ele deve aguardar o processo. Também, a imagem capturada mantém-se como plano de fundo durante todo o processo de espera.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{./Resources/capRes.png}
	\caption{Imagem capturada e seu respectivo resultado}
	\label{CapRes}
\end{figure} 

Quando o resultado enfim chega ao aplicativo, a animação e o som de processamento são interrompidos, o plano de fundo volta a mostrar as imagens da câmera, e sobre ela, abre-se uma caixa de texto translúcida e deslizável, conforme mostra a Figura \ref{CapRes}, contendo o texto descritivo em negrito e em fonte grande. Com um longo clique, ou no caso do Talkback estar ativado, um curto clique seguido de um longo sobre a tela, o texto é copiado para a área de transferência. O botão de retorno permite ao usuário voltar a câmera, e o botão de menu, o permite ativar ou desativar os efeitos visual e sonoro realizados durante a espera do processamento. Ao final, a descrição é salva na mesma pasta da imagem capturada.

\subsection{Implementação de opções de reconhecimento}
Com todo o tratamento dado ao conteúdo transcrito das imagens, para essa funcionalidade, foram criadas duas opções ligeiramente distintas para o aplicativo, como ilustra a Figura \ref{funcoes}. A primeira requisitaria apenas detecção de caracteres da imagem capturada com o intuito de reduzir o número de requisições, e possivelmente reduzir o tempo de resposta. Essa funcionalidade seria aplicável no caso específico de o usuário ter o conhecimento prévio de que a imagem poderia estar preenchidas por algum texto, e que essa informação sozinha pudesse ser relevante e suficiente.
A segunda funcionalidade solicitaria todas as informações possíveis ao Cloud Vision, que são: Textos, Rótulos, Logotipos, e Pontos turísticos. Por fim, ambas alternativas de extração de informação da imagens foram inseridas em dois dos quatro botões do menu principal.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{./Resources/funcoes.png}
	\caption{Comparação entre botões de solicitação de extração de informação de imagem}
	\label{funcoes}
\end{figure} 




\subsection{Registro de descrições}

A funcionalidade de transcrição de imagem em texto foi perfeitamente realizada. Mas para prover ao usuário a possibilidade de resgatar resultados anteriores, foi importante permitir que o aplicativo oferecesse a opção de salvar. Nesse ponto surgiu uma questão: Qual seria melhor forma de usuário acessar esse registro? 

Nomear os registros com parte da descrição poderia causar ambiguidade de nomes e poderia dificultar encontrá-los caso houvesse muitos. Assim, foi decidido que os registros seriam nomeados com a data e hora de criação. Além disso, seriam sempre ordenados temporalmente ao serem carregados na lista pelo aplicativo. Isso facilitou muito o acesso, pois os mais recentes apareciam no topo, e data/horário são identificadores únicos e permitem fácil localização na procura por um registro. A Figura \ref{select} apresenta uma lista de registros que foi gerada pela utilização do aplicativo.

Com isso decidido, foi necessário planejar a estrutura desse registro. A princípio considerou-se que o áudio referente à transcrição deveria ser salvo. No entanto, o propósito principal do aplicativo era apenas extrair informações de imagens e encontrar uma forma de fazer com que o usuário com deficiência visual pudesse acessá-la. Salvar o áudio deixou de ser necessário quando se percebeu que a função de áudio descrição é parte exclusiva da interface de acessibilidade do aplicativo, e não é obrigatória para todos os usuários. A intenção de salvar os dados não é pela voz da áudio descrição, mas exclusivamente por seu conteúdo.

Assim, cada registro correspondia a um diretório contendo apenas a foto no formato JPG, para referência de quem pode ver, e um arquivo no formato TXT contendo a descrição. A áudio descrição ficou sob responsabilidade da interface, após o carregamento do registro. Por fim, essa funcionalidade foi atribuída a um dos quatro botões do menu principal. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{./Resources/select.png}
	\caption{Lista de registros de descrição}
	\label{select}
\end{figure} 


\subsection{Tratamento de sinais ultrassônicos}
O tratamento de sinais vindos do sensor HC-SR04 é parte essencial do projeto, porém a mais simples de ser feita. Do ponto de vista de hardware, o sensor possui quatro pinos de conexão: VDD, GND, Trigger e Echo. O VDD foi conectado a alimentação de 5V do Arduíno, assim como o GND conectado ao terra. O Trigger e o Echo são respectivamente entrada e saída do sensor para que o sensor receba comando para emissão de ondas de 40 kHz de frequência e então retorne em sua saída o valor medido da reflexão da onda. Esses dois pinos foram conectados respectivamente nos Pinos 4 e 5 do Arduíno.

Do ponto de vista lógico, o programa que roda no Arduíno basicamente controla a emissão e recepção de sinais do sensor, e em seguida repassa para o módulo Bluetooth. O sensor aguarda a onda refletida, e baseado no tempo entre emissão e recepção, é possível calcular a distância percorrida até o obstáculo. O sensor tem capacidade de identificar obstáculos até 4 metros. Quando ocorre algum erro de medida, e a distância calculada é maior que esse limite, o valor é ignorado e não é reenviado ao Bluetooth.

\subsection{Comunicação Arduino-BlueTooth}

Para transmitir sinais do Arduíno para o smartphone via módulo BlueTooth, bastou inserir a informação na porta Serial. O mais importante foi, na verdade, decidir que informação deveria ser transmitida. Para garantir a modularidade do sistema, o Arduíno ficou encarregado apenas de enviar ininterruptamente os sinais lidos pelo sensor ao smartphone, sem realizar qualquer verificação de proximidade de obstáculos, função que o aplicativo Android ficou encarregado de fazer.

Do ponto de vista de circuitos, apenas quatro dos seis pinos do módulos foram utilizados. A razão foi que o HC-05 pode ser programado para ser mestre ou escravo. No modo escravo, os pinos KEY e STATE podem ser ignorados, e como não havia necessidade de o Arduíno se conectar a nenhum outro dispositivo, nem mesmo de requisitar conexões, esse foi o modo adotado para o BlueTooth no sistema. Foram então conectados VCC e GND aos respectivos pinos do Arduíno, para alimentar o módulo. O pino TXD de transmissão do módulo foi conectado ao pino RX do Arduíno, para recepção de sinais de comunicação vindos do smartphone. Por fim, o pino TX do Arduíno foi conectado ao RXD do módulo. Para adaptar a tensão de saída do Arduíno à tensão adequada do módulo, foi necessário implementar um circuito divisor de tensão, pois o sinal proveniente do Arduíno é de 5V porém a tensão recomendada do módulo é da ordem de 3V.

\subsection{Comunicação Smartphone-BlueTooth}

Do lado oposto da comunicação, no aplicativo Android foi necessário receber os dados do Arduíno. Para tanto, um ciclo de comandos foi executado em plano de fundo. Primeiramente, o BlueTooth era ligado e fazia-se uma varredura repetitiva de dispositivos ao redor. Caso encontrasse um com o nome HC-05, a varredura era interrompida e tentava-se iniciar um conexão. Ao ser iniciada, o aplicativo iniciava uma leitura contante do buffer de entrada e o dado, distância até um possível obstáculo, era tratado e gerava-se duas possíveis classificações: Surgimento de obstáculos no caminho ou Desaparecimento de obstáculos no caminho, ambos baseados em um limite mínimo definido de 1m. Quando um dos dois casos ocorresse, um alerta seria emitido, o qual seria lido pelo Talkback para informar o usuário. Essa funcionalidade por fim foi colocada com ação do último dos quatro botões do menu principal.

O circuito completo, contendo o sensor de obstáculos, o módulo bluetooth e o Arduíno, pode ser visualizado na figura \ref{circuit}.


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{./Resources/circuit.png}
	\caption{Circuito Arduíno com módulo BlueTooth e sensor de obstáculos}
	\label{circuit}
\end{figure}




