\chapter{Resultados e Discussões}
\label{Resultados}

Com as funcionalidades planejadas para o projeto finalmente implementadas, o passo seguinte foi a realização de testes. Esse capítulo será dividido em três seções tal que na primeira serão tratados dos resultados da extração de informação de imagens, a segunda tratará da performance do detector de obstáculos e a terceira fará uma análise de consumo do sistema.

\section{Descrição de Imagens}

Na descrição de imagens duas considerações foram necessárias para garantir o correto desempenho do sistema: o tempo de resposta, pois não é conveniente deixar o usuário esperando por muito tempo pela informação requisitada, e a porcentagem de erros dos resultados obtidos, para que o usuário receba informação confiável do aplicativo. Como a Google Cloud API é uma ferramenta online, a primeira dificuldade encontrada para eficiência de processamento foi o transporte de dados para o servidor da Google. Quanto mais dados são transmitidos pela rede e processados pela rotina no servidor, maior o tempo de latência para a resposta. Isso significa que a velocidade da Internet do usuário será sempre um limitador. 

De modo geral, também foram realizados testes sobre a interface para avaliação da corretude funcional do aplicativo após o término de cada módulo desenvolvido, e sempre que erros surgiam, puderam ser corrigidos. O aplicativo foi submetido ao Android Lollipop, versões 5.0.1 e 5.1.1, onde foram encontrados e corrigidos problemas de foco da câmera e de tamanho distorcido de alguns componentes da interface.


\subsection{Teste para diferentes dimensões de imagens}

Apesar de a velocidade da internet ser um fator limitante, a quantidade de dados transmitida, em alguns casos, pode ser flexibilizada uma vez que a imagem pode ter sua resolução reduzida e exibir um número menor de bytes para ser representada. Entretanto, essa redução resulta em um detalhamento menor da imagem, o que pode dificultar seu processamento, causar erros de interpretação de seu conteúdo e por fim não retornar resultados corretos.

A fim de confrontar resolução de imagem, tempo de processamento e erros dos resultados, para cada solicitação de extração de informação das imagens, a mesma imagem contida na Figura \ref{Teste-HP} foi enviada com diversas resoluções, e os tempos das fases do processo foram medidos. Já a Figura \ref{Resultado-HP} apresenta os resultados para três diferentes resoluções da Figura \ref{Teste-HP}. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.1]{./Resources/Teste-HP.jpg}
	\caption{Captura de imagem da etiqueta do computador HP, com defeito de flash, para descrição}
	\label{Teste-HP}
	%\caption*{Source: some source}
\end{figure}







\newsavebox\MBox
\newenvironment{MinipageGreen}[1]
{\par\smallskip\begin{lrbox}{\MBox}\begin{minipage}{#1}}
		{\end{minipage}\end{lrbox}%
	\makebox(0,0){\put(0,0){%
			\includegraphics[width=\wd\MBox,height=2\ht\MBox]{./Resources/green.jpg}
			}
	}%
	\usebox\MBox\par%
}
\newenvironment{MinipageRed}[1]
{\par\smallskip\begin{lrbox}{\MBox}\begin{minipage}{#1}}
		{\end{minipage}\end{lrbox}%
	\makebox(0,0){\put(0,0){%
			\includegraphics[width=\wd\MBox,height=2\ht\MBox]{./Resources/red.jpg}
		}
	}%
	\usebox\MBox\par%
}

\newenvironment{MinipageYellow}[1]
{\par\smallskip\begin{lrbox}{\MBox}\begin{minipage}{#1}}
		{\end{minipage}\end{lrbox}%
	\makebox(0,0){\put(0,0){%
			\includegraphics[width=\wd\MBox,height=2\ht\MBox]{./Resources/yellow.jpg}
		}
	}%
	\usebox\MBox\par%
}


\begin{figure}[H]
	
	\begin{subfigure}{.45\textwidth}
		
		
		\begin{MinipageGreen}{\textwidth} 
			
			\definecolor{green}{RGB}{140,255,26}
			
				\bf\color{white} nesta imagem está escrito: \color{green} HP 15 Simply perfect. Processing power Do it all at impressive Speeds with a next-generation AMD processor. Free 25GB lifetime cloud \color{red}00X \color{green}storage from Box Get your files from any Internet-connected device. HP TrueVision HD Webcam Capture all the details with vibrant clarity, even in low light. See disclaimers on product box. For complete details and terms of use, including cancellation policies, visit the website at www.box.com, Internet service required and not included.
			
		\end{MinipageGreen}
		
		\captionof{figure}{}
		\label{RI}
	\end{subfigure}		
	\begin{subfigure}{.45\textwidth}
		
		\begin{MinipageYellow}{\textwidth}
			
			\definecolor{green}{RGB}{0,179,0}
			%\definecolor{red}{RGB}{255,71,71}
			
			\bf\color{white}nesta imagem está escrito: \color{green} HP 15 Simply perfect. Processing \color{red}powe \color{green}Do it all at \color{red}impress peeds \color{green}with a next-generation AMD processor. Free 25GB lifetime cloud storage from Box Get your files from any Internet-connected device. HP True Vision HD Webcam Capture all the details with vibrant clarity, even in low light. See disclaimers on product box. For complete details and terms of use, including cancellation policies, visit the website at www.box.com Internet service required and not included.
			
		\end{MinipageYellow}
		\captionof{figure}{}
		\label{RII}
	\end{subfigure}		
	\begin{subfigure}{\textwidth}
	%\fbox{
	\vspace{1cm}
	

	\begin{MinipageRed}{\textwidth}
		
		\definecolor{red}{RGB}{255,128,128}
		
		\bf\color{white}nesta imagem está escrito: \color{green} HP 15 Simply perfect. Processing \color{red}powR mpress \color{green}next-generation \color{red}ANAL pluce sul \color{green}Free 25GB lifetime \color{red}duud \color{green}storage from Box Get your files \color{red}Ton Jny \color{green}Internet connected \color{red}cevice \color{green}HP \color{red}Tru BVision HU Webo am Copture \color{green}the detais with vibrant \color{red}darity, \color{green}even \color{red}inluw lilli. box for compl-1 use inclue inteinetsarute resu ie:
		
	\end{MinipageRed}
		\captionof{figure}{}
		\label{RIII}
	\end{subfigure}	
	\caption{Resultado da extração apenas de texto sobre a imagem da Figura \ref{Teste-HP} com as resoluções de (\protect\subref{RI}) 2560x1920, (\protect\subref{RII}) 1024x768 e (\protect\subref{RIII}) 480x360}
	\label{Resultado-HP}
\end{figure}

A Tabela \ref{Estat-HP} mostra que a resolução da imagem é proporcional ao tempo total de processamento da informação requisitada e inversamente proporcional a quantidade de erros do resultado. É fundamental lembrar que o tempo de processamento será sempre relacionado à velocidade da internet, portanto não são valores absolutos. O erro de cada imagem é calculado pela equação \ref{eqErro} a seguir:



\begin{equation}
\label{eqErro}
 Erro = \frac{\text{Número de caracteres na imagem} - \text{Número de caracteres corretos}}{\text{Número caracteres na imagem}}\times 100\% 
\end{equation}

\definecolor{googleBlue}{rgb}{0.17,0.52,0.91} 
\newcolumntype{a}{>{\columncolor{white}\color{black}}l}

\begin{table}[H]
	
	\centering
	
	\caption{Tempos das fases da transcrição de imagem sobre a etiqueta do computador HP, ilustrada pela Figura \ref{Teste-HP}}	
	
	\begin{tabular}{!{\color{black}\vrule} l  c c c !{\color{black}\vrule}}
		\arrayrulecolor{black} \hline
		\rowcolor{black}&\multicolumn{3}{c|}{\textcolor{white}{Resultados}}  \\\hline
		\rowcolor{black}								
							& \textcolor{white}{\ref{RI}} 	& \textcolor{white}{\ref{RII}}	& \textcolor{white}{\ref{RIII}}\\\hline
		Resolução             	& 2560x1920	    	& 1024x768          & 480x360  	       \\\hline
		Erro de reconhecimento	                & 0.8\%		    & 1.9\%              & 63.1\%	           \\\hline
		Tempo de compressão     		& 3667ms   		& 939ms		    	& 206ms  	       \\\hline
		Tempo de codificação    		& 570ms    	    & 69ms              & 66ms             \\\hline
		Tempo de transferência e processamento	& 103,849s	    & 17,871s   & 8,285s   	       \\\hline
		Tempo de reescrita              & 17ms		    & 97ms              & 4ms 	           \\\hline
		
		
	\end{tabular}
	\label{Estat-HP}	
\end{table}


Varias características importantes podem ser extraídas desses resultados. Primeiramente, a imagem possui um defeito causado pelo brilho intenso do flash concentrado num único ponto no momento da captura, e esse defeito afeta diretamente 3 palavras do texto. Essas palavras afetadas pelo brilho correspondem exatamente as malformadas, em vermelho, do resultado apresentado pela Figura \ref{RII}, erro esse que não ocorre com o apresentado pela Figura \ref{RI}. Isso permite a inferência de que a redução da resolução pode ter tornado a OCR menos precisa e esse problema ter sido potencializado pelo brilho do flash ao ponto de distorcer completamente a grafia das palavras. 

É possível que se o brilho refletido não tivesse sobreposto essas palavras, o resultado de \ref{RII} fosse quase idêntico ao de \ref{RI}. Essa hipótese pode ser confirmada pela Tabela \ref{bestPracticesTable}, pois as dimensões recomendadas pela Google para a detecção de texto correspondem as da Figura \ref{RII}. Além disso, dimensões inferiores reduzem a acurácia do resultado, o que pode ser confirmado pela Figura \ref{RIII}, enquanto superiores aumentam o tempo de processamento e uso da largura de banda sem necessariamente promover melhora significativa da acurácia\cite{bestPracticesGoogle}.


\begin{figure}[H]
	\centering
	
	\captionof{table}{Dimensões de imagem recomendadas para cada característica buscada}
	\includegraphics[scale=0.5]{./Resources/bestPractices.png}
	\caption*{Fonte: Google Cloud Platform\cite{bestPracticesGoogle}}

	\label{bestPracticesTable}
	
\end{figure}

\subsection{Teste para reconhecimento de texto girado}

Considerando o fato de que o usuário do aplicativo certamente não saberá de antemão qual a posição do texto do qual deseja obter informações, é possível ocorrer a captura de um texto disposto em diversos ângulos. Ao se realizar os testes sobre textos com diferentes posições angulares, identificou-se que entre -90° e 90° não há qualquer problema na extração de informação. Entretanto, acima desse limite, a aplicação simplesmente não consegue mais identificar os caracteres corretamente. O resultado obtido pode ser visualizado pela Figura \ref{posicoes}

\begin{figure}[H]
	
	\begin{subfigure}{5cm}
		
		\centering
		\includegraphics[scale=0.4]{./Resources/girado.png}
		\captionof{figure}{}
		\label{girado}
	
	\end{subfigure}		
	\begin{subfigure}{5cm}
		
		\centering
		\includegraphics[scale=0.4]{./Resources/girado90.png}
		\captionof{figure}{}
		\label{girado90}
		
	\end{subfigure}		
	\begin{subfigure}{5cm}

		\centering
		\includegraphics[scale=0.4]{./Resources/semgirar.png}
		\captionof{figure}{}
		\label{semgirar}
		
	\end{subfigure}	
	\caption{Extração apenas de texto de uma imagem sob três diferentes posições. (\protect\subref{girado}) 180°, (\protect\subref{girado90}) 90° e (\protect\subref{semgirar}) 0°}
	\label{posicoes}
\end{figure} 

Apesar de esse resultado mostrar que há uma limitação na capacidade de API reconhecer caracteres, é possível compreender a razão. Uma hipótese é que o algoritmo apenas verifique que há linhas horizontais de textos, e não considere a possibilidade de o texto estar virado em 180°. Então, ele deve comparar o simbolo invertido com os de sua base de dados, e o que se encaixar melhor é considerado o correto. Ao analisar com mais cuidado a Figura \ref{girado}, pode-se perceber que apesar de o texto retornado não ter qualquer significado real, existe uma razão na formação de cada simbolo. Há uma considerável semelhança entre a letra "a" girada de 180° e a letra "e", entre "L" e "1", entre "w" e "m", e assim por diante. Quanto a Figura \ref{girado90}, praticamente não houve erros durante a OCR, mesmo apresentando um texto girado de 90°, assim como o teste apresentado  pela Figura \ref{semgirar}.


\subsection{Teste para reconhecimento de texto manuscrito}

Uma das possibilidades de utilização do aplicativo seria a leitura de bilhetes escritos a mão. Alguns testes foram realizados para se ter conhecimentos dos limites das capacidades da API, quanto a escrita a mão, seja ela de forma ou cursiva. 

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.5]{./Resources/forma.png}
	\captionof{figure}{Resultado da extração de texto sobre imagem contendo escrita manual em letra de forma.}
	\label{forma}
	
\end{figure}




Os resultados mostraram que existe maior limitação da API quanto a identificação de caracteres manuscritos, se comparada a de digitais. A Figura \ref{forma} apresenta o caso de um texto capturado com a mais alta resolução que o aplicativo oferece, de 2560x1920 pixels, e mesmo assim há alguns erros de identificação. Porém, como é possível observar nas Figuras \ref{mao} e \ref{mao2}, os resultados só ficam gravemente incorretos quando os textos são escritos em letra cursiva. Nesse cenário, o reconhecimento até ocorre, mas de uma quantidade muito pequena do total de palavras, apresentando diversos erros, mesmo em traços largos e cor contrastante. 

É possível que a API não ofereça suporte para modelos de letra cursiva, uma vez que nos Estados Unidos, país sede da Google, esse tipo de escrita já vem sendo abandonado com o advento dos computadores pessoais e celulares nas últimas décadas\cite{letraMao}. Apesar de ser ter sido considerada uma decisão polêmica, as escolas já não mais são obrigadas a ensinar os alunos a escreverem em letra de mão. Por essa limitação da API, a transcrição de textos em letra cursiva se mostra, na prática, impossível pela aplicação.




\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.5]{./Resources/mao.png}
	\captionof{figure}{Resultados da extração de texto sobre imagem, em diferentes resoluções, contendo palavras manuscristas em letra cursiva.}
	\label{mao}	
\end{figure}

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.5]{./Resources/mao2.png}
	\captionof{figure}{Resultado da extração de texto sobre imagem contendo texto escrito em letra cursiva.}
	\label{mao2}	
\end{figure}


\subsection{Teste para rotulação de elementos da cena}

Saber o que se passa tendo conhecimento do que há ao redor é uma dos objetivos do projeto. Para saber o quais as limitações da API na detecção de objetos em imagens, foram realizados testes apontando a câmera para os mais diversos objetos a fim de se avaliar sua performance nesse quesito. A Figura \ref{dogLabels} apresenta o resultado completo retornado pela extração de rótulos da imagem de um cachorro. É possível perceber que características como "Cachorro de brinquedo" e "Yorkshire Terrier" não são aplicáveis ao animal da foto. Como o aplicativo só considera resultados com pontuação acima de 80\%, rótulos como esses, em vermelho, foram ignorados no resultado visualizado pelo usuário.

\iffalse
\begin{table}[H]
	
	\centering
	
	\caption{Tempos das fases da transcrição de imagem sobre a etiqueta do computador HP, ilustrada pela Figura \ref{Teste-HP}}	
	
	\begin{tabular}{ll}
		
		Atributo				& Pontuação \\
		Animal de estimação    	& 95\% \\		
		Cachorro		        & 94\% \\
		Animal    	            & 93\% \\
		Mamífero			    & 90\%      \\
		Cachorro de brinquedo   & 70\%	          \\
		Carnívoro      			& 68\%	          \\
		Yorkshire Terrier		& 52\%	          \\
	\end{tabular}
	\label{cachorro}	
\end{table}

\fi

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.5]{./Resources/labels.png}
	\captionof{figure}{Rótulos extraídos da imagem de um cachorro}
	\label{dogLabels}
	
\end{figure}

A escolha do valor mínimo de pontos para que cada rótulo fosse aceito foi puramente empírica. Apesar de ter resultado em boa descrição para a imagem da Figura \ref{dogLabels}, o valor escolhido que elimina alguns resultados subaproveitou os rótulos da imagem da Figura \ref{computerLabel}, descrevendo-a apenas como "Dispositivo", já que "Laptop", palavra mais adequada, foi ignorada.

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.4]{./Resources/labelsComputer.png}
	\captionof{figure}{Primeira extração de rótulos da imagem de um laptop}
	\label{computerLabel}
	
\end{figure}

A definição de um valor que simultaneamente seja capaz de descrever um elemento da cena e não sobrecarregue o usuário com informações, muitas vezes desnecessárias, não é tão simples, e uma descrição curta e detalhada dificilmente será conseguida. No entanto, o resultado não depende apenas da definição desse valor, mas também da própria imagem. A Figura \ref{computerLabel2} ilustra o mesmo laptop capturado novamente sob iluminação e posição diferentes. Nesse cenário, o resultado foi capaz de promover uma descrição mais detalhada do objeto em cena.

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.4]{./Resources/labelsComputer2.png}
	\captionof{figure}{Segunda extração de rótulos da imagem de um laptop}
	\label{computerLabel2}
	
\end{figure}

Nos casos citados, independentemente de qual foi o critério para ignorar alguns resultados, todos os rótulos quase sempre tiveram relação com o objeto na imagem. Entretanto, em algumas situações a API falhou em identificar ao menos um rótulo corretamente para a imagem capturada. A Figura \ref{cadeiraLabel} ilustra esse problema. Nela, foi capturada a imagem de uma cadeira, porém além de não haver resultados acima do limite mínimo de pontuação, nenhum dos quatro rótulos tem qualquer relação com a imagem.

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.4]{./Resources/labelCadeira.png}
	\captionof{figure}{Extração de rótulos da imagem de um cadeira}
	\label{cadeiraLabel}
	
\end{figure}

É possível que a explicação para esse resultado seja que o ambiente no qual a cadeira estava inserida tivesse afetado sua imagem capturada ao ponto de a API não ser capaz de identificar o que estava de fato em cena, e confundir o objeto com o para-choques de um veículo. Obviamente não é desejável que confusões como essa ocorram, entretanto, esse é um fenômeno parecido com a "ilusão de óptica". Ao analisar a imagem, percebe-se que as faixas escuras entre a parede e o chão, atrás da cadeira, somadas a sua estrutura em grades no meio podem ter sido avaliados como a parte frontal de um carro: Dois faróis pretos nas laterais, um capô branco no topo e para-choques com grades na porção centro-inferior.

\subsection{Teste para classificação de expressão facial}

Dentre as características que se pode obter de uma imagem, certamente a classificação de expressões faciais é a mais difícil de se obter. Como mostrou anteriormente a Tabela \ref{bestPracticesTable}, as dimensões recomendadas para a detecção de face é a maior dentre todas as outras características. Como apresentado na Seção 4.1, o tempo de resposta cresce significativamente conforme a dimensão da imagem aumenta. Isso significa que para se obter resultados corretos é necessário enviar a imagem com alta resolução e aguardar mais tempo. A Figura \ref{expressoes} apresenta o resultado obtido pela solicitação do serviço de detecção de faces e extração de suas expressões faciais. As imagens foram tiradas diretamente pela câmera do celular durante a execução do aplicativo a partir da exibição da tela do computador.

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.4]{./Resources/expressoes.png}
	\captionof{figure}{Expressões faciais detectadas em imagens de rosto}
	\caption*{Fonte das fotos: Google Imagens}	
	\label{expressoes}
	
\end{figure}

Apesar dos acertos nas descrições das faces, os resultados não foram sempre corretos. Foi possível perceber que a detecção de expressões de raiva e tristeza dificilmente ocorriam, mesmo com o aumento da qualidade da imagem, ou com faces expressivas. A Figura \ref{triste} apresenta casos de falha com imagens de faces com expressões de tristeza. Os resultados variaram desde a não identificação da expressão evidente até a incapacidade de encontrar a face.

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.4]{./Resources/triste.png}
	\captionof{figure}{Expressões faciais de tristeza não detectadas em imagens de pessoas tristes}
	\caption*{Fonte das fotos: Google Imagens}
	\label{triste}
	
\end{figure}




%\raggedright
\section{Detecção de Obstáculos}

Na implementação da funcionalidade de detecção de obstáculos, duas considerações precisaram ser feitas. Primeiramente, para atender aos resultados esperados pelo usuário, o sensor de obstáculos deveria ser preciso o suficiente para garantir um deslocamento confiável. Além disso, procurou-se reduzir ao máximo o tamanho do circuito, para garantir sua usabilidade.

\subsection{Precisão e acurácia das medidas de distância}

Assim que o circuito detector de obstáculos foi criado e apresentava resultados medidos pelo sensor, a tarefa seguinte foi verificar a confiabilidade dos dados. A Tabela \ref{ErroSensor} mostra os resultados das simulações para diferentes distâncias em relação a uma parede.

\newcolumntype{b}{>{\columncolor{googleBlue}\color{white}}m{4.4cm}}

\begin{table}[H]
	
	\centering
	
	\caption{Dados extraídos da simulação do sensor de obstáculos sobre distâncias variadas e conhecidas}	
	
	\begin{tabular}{!{\color{black}\vrule} l c c c c c c c c !{\color{black}\vrule}}
		\arrayrulecolor{black} \hline
		\rowcolor{black}   & \multicolumn{8}{c|}{\textcolor{white}{Simulações}}  \\\hline
		Distância Real (cm)		& 10 	& 20 	& 30 	& 40	& 50	& 100 & 200	 & 300 \\\hline
		Distância média aferida (cm) 
				& 15 	& 27 	& 39 	& 52	& 64 	& 127 & 256  & 384 \\\hline
		Desvio padrão (cm) 		& 0.70 	&0.80	& 0.80 	& 0.84	& 0.87 	& 0.92 & 0.93 & 1.01 \\\hline
		
		Número de amostras	& 336 	& 304 	& 348 	& 444	& 296 	& 453 & 481	 & 371 \\\hline
		Tempo de simulação (s)	& 21 	& 25 	& 31 	& 37	& 26 	& 42  & 41 	 & 42 \\\hline
		
		
		Distância ajustada (cm)    	& 11.01 & 20.42 & 29.83 & 40.03	& 49.44 & 98.85 & 200.03 & 300.42 \\\hline	
		
		
	\end{tabular}
	\label{ErroSensor}	
\end{table}

Nota-se que o sensor produziu valores precisos, uma vez que o desvio padrão foi no entorno de apenas 1cm. Entretanto, sua acurácia, que é a medida de quão próximo do valor real está do amostrado, poderia causar erros significantes de classificação de distância pelo aplicativo. Por essa razão, foi necessário inserir uma correção nos valores de distância lidos. Por meio do método dos mínimos quadrados, e baseado nas amostras das simulações foi obtida a equação \ref{eqDist} para o ajuste dos valores:
\begin{equation}
\label{eqDist}
Da = 0.78Ds - 0.75
\end{equation}
em que $Da$ representa a distância ajustada e $Ds$ a medida pelo sensor. Com essa adaptação, os resultados ganharam a acurácia necessária e atribuíram maior confiabilidade ao dispositivo.

\subsection{Usabilidade do detector de obstáculos}

Outro ponto considerado foi o tamanho dos elementos do circuito. Quanto menor e compacto, mais usável ele poderia se tornar. Como se tratava apenas de um protótipo, e devido à limitação dos materiais disponíveis para o projeto, foi criada uma caixa para o circuito com dimensões pouco superiores a média das de um smartphone. O resultado obtido pode ser visto na Figura \ref{circuito}.


\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.4]{./Resources/circuito.png}
	\captionof{figure}{Protótipo do circuito detector de obstáculos}
	\label{circuito}
	
\end{figure}


\section{Avaliação de consumo do sistema}

O consumo de energia certamente é um grande limitador na implementação de qualquer sistema. É importante portanto ter conhecimento da potência dissipada tanto pelo aplicativo executado no smartphone, quanto do circuito detector de obstáculos, formado pelo Arduíno e demais módulos.

\subsection{Consumo no smartphone}

Na avaliação de consumo do aplicativo rodando no smartphone utilizou-se o Power Tutor, um aplicativo que mede o consumo de outros aplicativos no Android, e pode ser baixado gratuitamente pela Play Store. Uma vez ligado, ele avalia todos os processos que são executados pelo Android. A Figura \ref{phoneBattery} ilustra os resultados obtidos pela avaliação do aplicativo em um intervalo de 300 segundos. Entre os instantes 30 e 90 segundos o aplicativo se manteve conectado ao detector de obstáculos, e entre os instantes 120 e 240 segundos permaneceu na função de reconhecimento de texto. 

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.3]{./Resources/smartphoneBateria.png}
	\captionof{figure}{Potência consumida pelo aplicativo no smartphone pela solicitação de OCR e pela conexão com o detector de obstáculos}
	\label{phoneBattery}
\end{figure}

É possível notar que durante a solicitação de reconhecimento de texto houve um maior consumo da CPU do que durante o processo de detecção de obstáculos. O resultado faz sentido, uma vez que na primeira funcionalidade utiliza-se mais recursos como Wifi, câmera (captura, flash e preview), animação e som de processamento. Na detecção de obstáculos apenas o dispositivo Bluetooth do smartphone é utilizado.

Além disso, o consumo da bateria se dá muito mais pela iluminação da tela do que pela CPU. O gráfico de consumo pelo LCD apresentou descontinuidade nos dados devido o fato de o aplicativo ter sido desligado entre os testes. Na média, a potência consumida pelo aplicativo para a utilização das duas principais funcionalidades do sistema foi de 404mW.

\subsection{Consumo no detector de obstáculos}

Para avaliar com maior precisão o consumo de energia do circuito, durante 80 segundos foi medida a corrente consumida. Inicialmente, o circuito permaneceu ligado, porém o aplicativo do smartphone estava desligado. Aos 30 segundos o aplicativo foi ligado e a função de detecção de obstáculos foi acionada. Nesse instante nota-se pela Figura \ref{ligaArduino} que houve uma queda na corrente. Isso ocorreu porque quando o módulo Bluetooth é alimentado, mas não está conectado, ele fica constantemente enviando sinais para notificar sua presença. Quando uma conexão é estabelecida, ele passa a enviar apenas os sinais de comunicação, o que requer menos energia.

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.7]{./Resources/ligaArduino.png}
	\captionof{figure}{Corrente elétrica consumida pelo circuito antes, durante e após a conexão com o smartphone}
	\label{ligaArduino}
	
\end{figure}

Além de avaliar o consumo do circuito como um todo, avaliou-se também o quanto cada módulo conectado e devidamente ligado consome do total. Os módulos foram ativados de modo alternado a fim de se medir a corrente consumida individualmente, e para cada caso teste, o valor foi medido durante 25 segundos. O resultado pode ser visualizado pela Figura \ref{Modulos}, que mostra que a maior parte do consumo é resultado do funcionamento do dispositivo Bluetooth.

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.6]{./Resources/Modulos.png}
	\captionof{figure}{Corrente elétrica consumida pelo circuito discriminando o papel de cada módulo}
	\label{Modulos}
	
\end{figure}

A partir dos valores amostrados de corrente consumida pelo circuito, foi possível calcular a corrente média, o desvio padrão e a potência média, apresentados pela Tabela \ref{valoresMedios}. A potência $P$ foi calculada baseado no valor médio de corrente $I$ e na tensão $V$ de alimentação de 9.6V, pela equação \ref{eqPot}:
\begin{equation}
\label{eqPot}
P = V x I
\end{equation}


\definecolor{googleBlue}{rgb}{0.17,0.52,0.91} 
\newcolumntype{a}{>{\columncolor{googleBlue}\color{white}}l}

\begin{table}[H]
	
	\centering
	
	\caption{ Valores médios de corrente e potência consumidos pelos módulos do circuito}	
	
	\begin{tabular}{!{\color{black}\vrule} l  c c c c!{\color{black}\vrule}}
		\arrayrulecolor{black} \hline
		\rowcolor{black}
						& \textcolor{white}{Arduíno} 	& \textcolor{white}{Sensor}	& \textcolor{white}{Bluetooth} & \textcolor{white}{Conjunto} \\\hline
		Corrente Média(mA)  & 55		& 3.04      & 42.2       & 100.55\\\hline
		Desvio Padrão (mA)	& 1			& 0.09		& 0.42      & 0.38  \\\hline
		Potência Média(mW)  & 529.5  	& 29.3    	& 406.2	    & 968.3 \\\hline		
		
	\end{tabular}
	\label{valoresMedios}	
\end{table}

De fato, o módulo Bluetooth consome pouco menos que o Arduíno, mas isso representa quase a metade do consumo total. A Figura \ref{pizza} ilustra o resultado em percentuais de consumo.

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.7]{./Resources/pizza.png}
	\captionof{figure}{Porcentagem de potência consumida por cada módulo do circuito}
	\label{pizza}
	
\end{figure}





